---
title: "hw7"
author: "Shangjun Jiang"
date: "July 27, 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
#setwd("~/Desktop/Stats R/githubrepos-jennyjiang95/hw7")
# libraries go here
library(xml2)
library(rvest)
library(ggplot2)
library(lubridate)
library(stringr)
library(dplyr)
library(tidyr)
library(readr)
library(ggmap)
library(maps)
library(mapdata)
library(shiny)
library(rsconnect)
```

## Introduction

In a superficial way, this assignment is meant to make sure you're familiar with plotting spatial data.  However, the bulk of your time will most likely be devoted to wrangling and reshaping the data so that it's ready to be gr aphed.  As we move into the final stretch of the class, the hints will now become more sparse.  As with all the previous homeworks, there's no need to look up fancy packages or techniques.  Everything can be done with the tools we already have unless stated otherwise.

## The Data
The data are in the form that they were originally collected (except someone was nice enough to gather all the lat/long coordinates of the zip codes for you).

The data come from a Dialect Survey conducted by Bert Vaux.  Some limited information can be found at the original depracated website [http://www4.uwm.edu/FLL/linguistics/dialect/index.html](http://www4.uwm.edu/FLL/linguistics/dialect/index.html).  Although 122 questions were asked in the survey, the subset of the data provided to you only contains answers to the 67 questions that focused on lexical rather than phonetic differences.

There are three files included in this assignment:

* `question_data.Rdata`, an Rdata file containing
    + `quest.mat` a data frame containing the questions
    + `all.ans`, a list of data frames containing answers to the questions
* `lingData.txt`, a space-separated data table where each observation represents a response to the survey
    + `ID` a unique ID for each participant
    + `CITY` self-reported city of the participant
    + `STATE` self-reported state of the participant
    + `ZIP` self-reported zip code of the participant
    + `lat/long` coordinates calculated from the center of each zip code
    + `Q50-Q121` the participant's response to a question.  Some questions are missing in this range.  A value of 0 indicates no response.  Other numbers directly match their corresponding letter e.g. `1` should match with `a`.
* `lingLocation.txt` an aggregated data set.  The responses from `lingData.txt` were turned into binary responses (e.g. "1 if Participant answered a on question 50 and 0 otherwise").  The data were then binned into 1 degree latitude by 1 degree longitude "squares".  Within each of these bins, the binary response were summed over individuals.
    + `Cell` a unique ID for each lat/long bin
    + `Latitude/Longitude` coordinates for the cell
    + `V4-V471` the number of responses for the corresponding question and answer in the cell.  `V4` corresponds to response `a` to question `50` while `V468` corresponds to answer `g` for question `121` (the very last answer to the last question)
    
Note that while the rows represent the same _data_ in `lingData.txt` and `lingLocation.txt`, they are different _observational units_.  For example, say John and Paul take this questionnaire for two questions. The first question has three answer choices and the second question has four answer choices. If John answered A and D and Paul answered B and D, then `lingData` would encode two vectors: `(1, 4)` and `(2, 4)`. If they lived in the same longitude and latitude box, then it would be encoded in `lingLocation` as one vector: `(1, 1, 0, 0, 0, 0, 2)`.
    
You'll need `read_delim` from the `readr` package to read in the last two files.  Remember to specify the `delim` argument, which demarcates how fields are separated in the text file.

## Task 0
Explore and clean the data.  Document what was added/removed, explaining your actions.
```{r}
# Your cleaning code.
## load the data set
data <- read_delim("lingData.txt",
                   delim = " ")

location <- read_delim("lingLocation.txt",
                       delim = " ")

load("question_data.RData")
question <- quest.use
question$qnum <- as.integer(question$qnum)

# all.ans, a list of data frames containing answers to the questions
## find the answer and its frequency
listanswer = list()
i = 1
while (i <=length(all.ans)){
  listanswer[i] <-length(all.ans[[i]]$qnum)
  i <- i +1
}
max(unlist(listanswer))  #21

# create an answer data frame
answer = data.frame(all.ans[1])
names(answer) = c("qnum", "opt", "per", "ans")
i = 2
while (i <= (length(all.ans))){
  aa = data.frame(all.ans[i])
  names(aa) = c("qnum", "opt", "per", "ans")
  answer = full_join(answer, aa, by = names(aa))
  i = i +1
}

#get only matching questions and answers
answer <- answer %>%
  filter(qnum %in% question$qnum)

answer$qnum <- as.character(answer$qnum)
question$qnum <- as.character(question$qnum)


#combine question, data datasets together
comb <- gather(data,
       key = qnum, 
       value = opt, 
       -CITY,-ZIP,-lat,-long,-STATE, -ID) %>% 
  mutate(qnum = str_replace(qnum, "^Q0?", "")) %>% 
  mutate(opt = factor(opt,
                      labels =letters[1:21],  #21 answer
                      levels=c(1:21))) %>% 
  left_join(answer, by = c("qnum", "opt")) %>% 
  left_join(question, by = "qnum")

#find the most common answer for each state
statemax <- comb %>% 
  group_by(quest,STATE,ans) %>% 
  tally %>% 
  group_by(STATE, quest) %>% 
  filter(n==max(n)) 

statemax$STATE <- state.name[match(statemax$STATE,state.abb)]
statemax$STATE <- tolower(statemax$STATE)
names(statemax) <- c("quest","region","ans","n")

#deal with the tie data
nstate <- na.omit(statemax) %>% 
  group_by(quest,region) %>% 
  mutate(ans=paste(ans, sep = "", collapse = "/")) %>% 
  unique()

#get group and region
states <- map_data("state")
#combine dataset
cleaned <- left_join(states,nstate, by = "region")

write.csv(cleaned, "cleaned.csv")


```
# __A paragraph explaining your cleaning process__
 ######################################## QUESTION 1 ########################################
1. I first load all the dataset using read_delim and load data. I name them as data (data table contains the response) and question (contains 'quest.mat' AND 'all.ans'). 
2. I created a data frame 'answer' that contains the answers to the question in the 'question'. I also tried to get every answer's length for future use. (since in the future, I will convert them into letters so I need to know the max, which is 21.)
3. Then I updated the 'answer' dataframe by subsetting the question dataset which matches the data in the answer, since some data are missing.
4.Then I gathered the 'data' dataframe to  get the number of answers for every question. I combined the gathered 'data' with 'answer' and 'question' together to create a 'comb' dataframe. (which contains the answer, question, ID, long, lat, etc..)
5. Then I tried to find the most common answers for each state and named 'statemax'. 
6. After finding the most common answers, I dealed with the tie data (which used the paste) and also the deleted NA values and named 'nstate'
7. Then I joined the 'nstate' with the state data so I can graph them in ggplot. 


 ######################################## QUESTION 2 ########################################


```{r}
# extract data for these two visualizations. 
location <- read_delim("lingLocation.txt",
                       delim = " ")
# Question 51:
# # "Would you say 'Are you coming with?' as a full sentence, to mean 'Are you coming with us?'"
# listanswer[2] #4  V13+3 = V15

# Question 55:
# "I do exclusively figurative paintings anymore"
#listanswer[6] #3  V26+3 = V28

#before. #4
#listanswer[1] #9  V4+9 = V12
#listanswer[2] #4  V13+3 = V15
#listanswer[3] #3  V16+3 = V19
#listanswer[4] #3  V20+3 = V22
#listanswer[5] #3  V23+3 = V25
#listanswer[6] #3  V26+3 = V28


#GET THE DATA FOR QUESTION 1 & QUESTION 2
location51 <- data.frame(location[1:4],location[14:16])
location55 <- data.frame(location[1:4],location[26:28])
#Change the name
names(location51) <- c("Cell", "Number_of_people","lat","long", "a","b","c")
names(location55) <- c("Cell", "Number_of_people","lat","long", "a","b","c")

#gather data. 
loc1 <- gather(location51, key = opt, value = n, -Number_of_people, -Cell, -lat, -long)
loc2 <- gather(location55, key = opt, value = n, -Cell, -Number_of_people, -lat, -long)

#get the data from answer
q51 <- filter(answer,qnum=="51")
q55 <- filter(answer,qnum=="55")

#combine with answer + get the number
q1 <- left_join(loc1,q51, by = "opt") %>%
      group_by(Cell) %>% 
      filter(n==max(n))

q2 <- left_join(loc2,q55, by = "opt") %>% 
      group_by(Cell) %>% 
      filter(n==max(n))


#filter out the unnecessary columns
q1$per <- NULL
q1$opt <- NULL
q1$qnum <- NULL
names(q1) <-c("Cell", "Number_of_people","lat","long","n","ans")

q2$per <- NULL
q2$opt <- NULL
q2$qnum <- NULL
names(q2) <-c("Cell", "Number_of_people","lat","long","n","ans")

#deal with the tie dataset
q1<- q1 %>% 
  mutate(ans=paste(ans, sep = "", collapse = "/")) %>% 
  unique()

q2<- q2 %>% 
  mutate(ans=paste(ans, sep = "", collapse = "/")) %>% 
  unique()

```


I first loaded the dataset by using read_delim. 
Since I'm interested in question 1 and question 2. So I subsetted the location data into 'location 1' and 'location 2'.
Then I gathered the data together by the option (a,b,c,d). 
Then I get the data from the answer dataframe.Then I combined these two dataset together.
Then, similar to Question 1, I filtered and get the maxmium number in each family. 
Next, I filterred out the unncessary columns. 
Last, similar to what I did in Question1, I dealed with the tie dataset by combine them together.




## Task 1

Implement a Shiny App that colors a map of the continental US based off the most common answer for each state. The user should be allowed to pick one of the 67 questions from a dropdown menu.  If a state has two or more answers that tied, the map should show the tie as a different color.  A static example with a tie in West Virginia is shown below:

As with homework 6, include your server and ui code below along with a link to your app on shinyapps.io.
```{r ui, eval = FALSE}
# ui code

library(shiny)
library(readr)


load("question_data.RData")
question = quest.use

shinyUI(fluidPage(
  
  #  Application title
  titlePanel("States vs word choices"),
  
  # Sidebar with sliders that demonstrate various available
  # options
  sidebarLayout(
    sidebarPanel(
      # Simple integer interval
      selectInput("question", "Question:",
                  choices = question$quest),
 
      submitButton("Submit")
    
      ),
    
    
    mainPanel(
      plotOutput("Plot")
    )
  )
))

```

```{r server, eval = FALSE}
# server code

library(shiny)
library(dplyr)
library(stringr)
library(ggplot2)
library(readr)

cleaned <- read_csv("cleaned.csv")
names(cleaned) <- c("number","quest","ans","n","long","lat","group")

shinyServer(function(input, output) {
  
  output$Plot <- renderPlot({
      
    cleaned1 <- cleaned %>% 
      filter(quest == input$question)
    
    ggplot(cleaned1) + 
      geom_polygon(aes_string(x = "long", y = "lat", fill = "ans", group = "group"), 
                   color = "black") + 
      coord_fixed(1.3)+
      scale_fill_discrete(labels = function(x) str_wrap(x, width = 20))+
      labs(title = input$question)
    
  })
  
})

```
[The link to the app I created](https://shangjunjiang.shinyapps.io/wordchoice/)

## Task 2

Make visualization(s) of the `lingLocation` data for two questions that you found interesting.  Remember that each row represents a 1x1 square centered at the given lat/long coordinate.


```{r}
# plot code goes here
 ######################################## QUESTION 1 ########################################
ggplot(q1) + 
      geom_point(aes_string(x = "long", 
                            y = "lat", 
                            color = "ans", 
                            size="Number_of_people"),
                            alpha = 0.7)+ 
      coord_fixed(1.3)+
      theme(text = element_text(size=10))+
      labs(title = "Would you say 'Are you coming with?' as a full sentence, to mean 'Are you coming with us?'")+
      guides(size = FALSE, alpha = FALSE)


 ######################################## QUESTION 2 ########################################
ggplot(q2) + 
      geom_point(aes_string(x = "long", 
                            y = "lat", 
                            color = "ans", 
                            size="Number_of_people"),
                            alpha = 0.7)+ 
      coord_fixed(1.3)+
      labs(title = "I do exclusively figurative paintings anymore'")+
      guides(size = FALSE, alpha = FALSE)

```

